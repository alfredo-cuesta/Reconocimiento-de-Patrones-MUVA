{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas multiclase\n",
    "\n",
    "Hasta ahora sólo hemos atacado el problema de clasificación binaria. \n",
    "Pero frecuentemente nos encontraremos con conjuntos de datos donde hay varias clases y varias etiquetas\n",
    "+ multiclase: los ejemplos del conjunto de datos se agrupan en un conjunto finito de clases diferentes.\n",
    "+ multietiqueta: cada ejemplo puede tener una o varias etiquetas.\n",
    "\n",
    "En este cuaderno vamos a ver algunos métodos para abordad este tipo de problemas. \n",
    "\n",
    "---\n",
    "    [ES] Código de Alfredo Cuesta Infante para 'Reconocimiento de Patrones'\n",
    "       @ Master Universitario en Visión Artificial, 2021, URJC (España)\n",
    "    [EN] Code by Alfredo Cuesta-Infante for 'Pattern Recognition'\n",
    "       @ Master of Computer Vision, 2021, URJC (Spain)\n",
    "\n",
    "    alfredo.cuesta@urjc.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../MyUtils/')\n",
    "import MyUtils as my\n",
    "seed = 1234 #<- random generator seed (comment to get randomness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar datos desde OpenML a dataframes\n",
    "+ [OpenML](https://www.openml.org/d) es un repositorio con miles de conjuntos de datos\n",
    "+ Scikit-learn es capaz de descargarse un conjunto dado con el método `fetch_openml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw is a dataframe of 70000 rows and 784 cols.\n",
      "Y_raw is a dataframe of 70000 elements.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data from OpenML ('mnist_784')  ** it will take a minute **\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X_raw, Y_raw = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Store it in a dataframe\n",
    "X_raw = pd.DataFrame(X_raw)\n",
    "Y_raw = pd.DataFrame(Y_raw,columns=['label'])\n",
    "\n",
    "# Check\n",
    "strlog = \"X_raw is a dataframe of %d rows and %d cols.\"%(X_raw.shape[0], X_raw.shape[1])\n",
    "print(strlog)\n",
    "strlog = \"Y_raw is a dataframe of %d elements.\"%(Y_raw.shape[0])\n",
    "print(strlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar el conjunto de test y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "\n",
    "test_size = 0.1\n",
    "X_, Y_, X_test, Y_test = my.single_stratified_split(X_raw, Y_raw, \\\n",
    "                                                    test_size=test_size, random_state=seed)\n",
    "\n",
    "# Validation set\n",
    "\n",
    "valid_size = 0.2\n",
    "X_train, Y_train, X_valid, Y_valid = my.single_stratified_split(X_, Y_, \\\n",
    "                                                                test_size=valid_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "#### Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering, selection and rescaling to [0,1]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "theta = 0.3\n",
    "X = my.mnist_features( pd.DataFrame(X_train), theta=theta ) \n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = Y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fit*\n",
    "+ One vs. One (OvO)\n",
    "+ One vs. Rest (OvR) \n",
    "\n",
    "Ambos necesitan de un clasificador \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvO produces 45 classifiers\n",
      "OvR produces 10 classifiers\n"
     ]
    }
   ],
   "source": [
    "# this cell will take a while !! \n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "base_clf = SVC(kernel='rbf', degree=2, gamma=1, random_state = seed) #<- it can be any other one\n",
    "\n",
    "# Train OvO - SVM\n",
    "\n",
    "OvO_clf = OneVsOneClassifier(base_clf)  \n",
    "OvO_clf.fit(X,Y)\n",
    "\n",
    "# Train OvR - SVM\n",
    "\n",
    "OvR_clf = OneVsRestClassifier(base_clf)\n",
    "OvR_clf.fit(X,Y)\n",
    "\n",
    "# Check\n",
    "\n",
    "strlog = \"OvO produces %d classifiers\" %(len(OvO_clf.estimators_)) \n",
    "print(strlog)\n",
    "strlog = \"OvR produces %d classifiers\" %(len(OvR_clf.estimators_)) \n",
    "print(strlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación\n",
    "¡ Recordar que a los datos debemos aplicarles el mismo procedimiento que recibieron los de entrenamiento !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering, selection and rescaling to [0,1]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_pred = my.mnist_features( pd.DataFrame(X_valid), theta=theta ) \n",
    "X_pred = scaler.transform(X_pred)\n",
    "Y_true = Y_valid.values.ravel()\n",
    "\n",
    "# predict\n",
    "\n",
    "Y_pred_OvO = OvO_clf.predict(X_pred)\n",
    "Y_pred_OvR = OvR_clf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OvO confusion matrix:\n",
      "\n",
      "[[ 921    5   80   50    2   47   43    4   84    7]\n",
      " [  21 1094   57   52    1    1   32    4  122   34]\n",
      " [  49   45  744  150   79   33   75    4   41   38]\n",
      " [  14   51  138  848    0   18   14   53  102   47]\n",
      " [   3    4   33    0  967    3   79    3    3  133]\n",
      " [ 130   32   82  124    5  294   65   88  254   62]\n",
      " [  26   52   90    7   71    7  935    0   16   34]\n",
      " [  11   14    3   15    9   30    1 1038  114   78]\n",
      " [  40   83   28  134    3   64   45   61  708   63]\n",
      " [  12   55   40   33  175   10   44   53   59  771]]\n",
      "\n",
      "\n",
      "OvO Hits  = 8320\n",
      "OvO Fails = 4280\n",
      "\n",
      "OvR confusion matrix:\n",
      "\n",
      "[[ 987    4   69   55    4   27   50    7   33    7]\n",
      " [  29 1101   56   62    3   11   61    8   56   31]\n",
      " [  73   47  704  172   90   23   76    7   19   47]\n",
      " [  27   56  110  899    0   15   23   62   44   49]\n",
      " [   4    8   33    0  986    5   95    3    3   91]\n",
      " [ 207   46   71  163    7  246   95  129  101   71]\n",
      " [  33   53   80   10   92    5  943    0    9   13]\n",
      " [  15   19    1   19   12   28    2 1088   61   68]\n",
      " [  88  127   32  231    8   77   68  101  442   55]\n",
      " [  16   74   37   33  219   26   52   68   38  689]]\n",
      "\n",
      "\n",
      "OvR Hits  = 8085\n",
      "OvR Fails = 4515\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "conf_mat_OvO = confusion_matrix(Y_true,Y_pred_OvO)\n",
    "hits_OvO = np.trace(conf_mat_OvO)\n",
    "conf_mat_OvR = confusion_matrix(Y_true,Y_pred_OvR)\n",
    "hits_OvR = np.trace(conf_mat_OvR)\n",
    "\n",
    "# Print out\n",
    "print(\"\\nOvO confusion matrix:\\n\")\n",
    "print(conf_mat_OvO)\n",
    "print(\"\\n\")\n",
    "print( \"OvO Hits  = %d\"%(hits_OvO) ) \n",
    "print( \"OvO Fails = %d\"%(Y_true.shape[0]-hits_OvO) )\n",
    "print(\"\\nOvR confusion matrix:\\n\")\n",
    "print(conf_mat_OvR)\n",
    "print( \"\\n\")\n",
    "print( \"OvR Hits  = %d\"%(hits_OvR) ) \n",
    "print( \"OvR Fails = %d\"%(Y_true.shape[0]-hits_OvR) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios\n",
    "+ Hemos comprobado que, con el método `fit`, OvO genera un clasificador para cada par de etiquetas posible mientras que OvR genera un clasificador por cada etiqueta.\n",
    "+ Evidentemente el tiempo de computo es superior a un problema con dos clases.\n",
    "+ Por otro lado, el método `predict` devuelve una sóla clase, independientemente de haber usado OvO ó OvR.\n",
    "+ En este cuaderno hemos utilizado SVM, pero se podría haber utilizado cualquier otro clasificador base.<br>\n",
    "  Muchos de ellos tienen una opción para trabajar en problemas multiclase.\n",
    "     + Por ejemplo, en la ayuda de [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) podemos ver lo siguiente:\n",
    "     > + **decision_function_shape**{‘ovo’, ‘ovr’}, default=’ovr’ <br>\n",
    "       Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (‘ovo’) is always used as multi-class strategy.<br>\n",
    "       The parameter is ignored for binary classification. <br>\n",
    "     > + **break_ties**, default=False <br>\n",
    "     If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.\n",
    "+ La función *Softmax* resuelve mejor el problema multiclase, pero no elimina la tarea de aprender varios clasificadores. Sin embargo, en redes neuronales la usaremos continuamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
